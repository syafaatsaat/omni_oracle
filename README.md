# Projects by Omni Oracle

As part of a Data Engineering bootcamp, our team has done two projects to get hands-on experience in building an ETL pipeline to derive insights on the data that we collected. 
The projects are done within 3 weeks using the skills and knowledge we get from DataCamp which is a self-directed learning platform and the guidance of our lecturer, Christine.

# IMDb Movies Data Pipeline

![imdb_top_250|100](https://syafaatsaat.github.io/portfolio/assets/images/imdb_top_250.jpg)

This was the first project done during the bootcamp. We were assigned a task to explore or source for different types of data, build a data crawler, store the crawled data in a Database Management System (DBMS), and build an ETL data pipeline.

We based our data on the top 250 movies listed on the IMDb website and sourced out more data from the OMDb and TMDB websites. The transformation of the data is done using Python and some open-source libraries in Jupyter Notebook. Lastly, we stored the data in PostgreSQL where we designed the database schema, tables and entity-relationship models. I mainly contributed to the development of the data pipeline due to my strength in Python programming.

# Olist Store (Brazilian E-Commerce) Data Pipeline

![olist|100](https://syafaatsaat.github.io/portfolio/assets/images/olist.jpg)

This was the second project done during the bootcamp. We were assigned a task to formulate an architecture solution in creating an ETL/ELT pipeline to ingest a dataset and carry out data analysis to provide strategic recommendations on a business intelligence dashboard using Power BI. For this project, we tried to explore the Azure cloud services provided by Microsoft to create the architecture solution.

The data that we are working with is the Olist Store which is a Brazilian online marketplace. I was mainly tasked to create the pipeline in the Azure cloud services.
