{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90e25a99-d68e-4b92-874b-5a6e32570d1d",
   "metadata": {},
   "source": [
    "# Step 1: Extraction Process\n",
    "\n",
    "## Internet Movie Database (IMDb)\n",
    "The data or dataset that we will be working with are movies. Since we need a source for movie data, we looked at the Internet Movie Database ([IMDb](https://www.imdb.com/)) website. However, there is an issue with the IMDb website. It is no longer fully open-source friendly and has since opened a paid option for a wider range of dataset. The amount of data that are freely provided by IMDb are not enough for us to work with. However, we take IMDb as a starting point for our data extraction process because it has nicely provided a list of the top 250 movies which is the base of the problem statement that we are thinking of.\n",
    "\n",
    "## Open Movie Database (OMDb)\n",
    "Due to the scarcity of data from IMDb, we are exploring other sources of databases found in the Internet. We found 2 websites that provided APIs for gathering data from their database. One of it is the Open Movie Database API ([OMDb API](https://www.omdbapi.com/)). The OMDb API is a RESTful web service to obtain movie information, all content and images on the site are contributed and maintained by their users.\n",
    "\n",
    "## The Movie Database (TMDB)\n",
    "The other website/database that we have sourced is The Movie Database ([TMDB API](https://www.themoviedb.org/)). TMDB is a community built movie and TV database. Every piece of data has been added by their amazing community dating back to 2008. TMDB's strong international focus and breadth of data is largely unmatched and something they're incredibly proud of.\n",
    "\n",
    "The reason why we are gathering data from two databases is that we wanted to gather as much data as we could so that we have a lot of data to work with and to fill in some missing data. As we go down the notebook, there will be explanations on how we gather data from the stated sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863d31b5-1503-4622-9f06-510ce0e6a487",
   "metadata": {},
   "source": [
    "### Installing the needed modules and importing the packages used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e782a5-8a37-4813-89cc-0088d6139171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the module if needed. if installed, the cell will just print that it has been installed before and move on.\n",
    "!pip install certifi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "390ed79a-012e-4252-9fca-5f3e19a950a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# urllib3 is a powerful, user-friendly HTTP client for Python\n",
    "# to handle  data retrieval\n",
    "import urllib3\n",
    "from urllib3 import request\n",
    "\n",
    "# to handle certificate verification\n",
    "import certifi\n",
    "\n",
    "import os.path\n",
    "\n",
    "# to manage json data\n",
    "import json\n",
    "\n",
    "# for pandas dataframes\n",
    "import pandas as pd\n",
    "\n",
    "# Import Selenium Modules\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# Import Time\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# for connecting to the web for extracting data\n",
    "import requests\n",
    "\n",
    "# for working with csv files\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb405c2-0fb8-4b21-98bc-18e0b738ab0f",
   "metadata": {},
   "source": [
    "### These are global variables to be used for connecting with the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa0487ba-ee68-4e10-b143-831e0deaee78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle certificate verification and SSL warnings:\n",
    "# reference https://urllib3.readthedocs.io/en/latest/user-guide.html#ssl\n",
    "http = urllib3.PoolManager(\n",
    "    cert_reqs='CERT_REQUIRED',\n",
    "    ca_certs=certifi.where())\n",
    "\n",
    "# access token for TMDB API\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer eyJhbGciOiJIUzI1NiJ9.eyJhdWQiOiI2ZGYzM2RhMWRiMmMxZDE1MzU0YTFkNDI2YWQyODYzMCIsIm5iZiI6MTcyMzY5NDkwMi4xMzQ2MjcsInN1YiI6IjY2YmQ2MGQ2Y2ZjNTYwN2FmMGU5YjNhYSIsInNjb3BlcyI6WyJhcGlfcmVhZCJdLCJ2ZXJzaW9uIjoxfQ.8-71HQaSOlHGMGP3SLk6awUAuQyPaai43JSXK2AS8o8\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9175d576-bdc7-4b1f-a568-e4b24444d065",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "These two functions are created for exporting DataFrames to `.csv` files, and importing `.csv` files and converting them to a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5521ec2-5a20-4186-930c-72a5b3b3142d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting the DataFrame to a .csv file\n",
    "def export_dataframe_to_csv(df, file_name):\n",
    "    df.to_csv(file_name, index=False, encoding='utf-8-sig')\n",
    "\n",
    "# importing the .csv file and converting it to a DataFrame\n",
    "def read_csv_to_dataframe(file_name):\n",
    "    return pd.read_csv(file_name, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae361003-f5b3-46eb-b360-76aba45f4c24",
   "metadata": {},
   "source": [
    "## Data Extraction Functions\n",
    "\n",
    "I have split up the entire data extraction process into multiple functions for a number of reasons. \n",
    "Firstly, it is because of the sheer amount of code and it can get confusing when things start to break. \n",
    "Secondly, this is done to make things simpler by breaking the steps and tasks done to smaller tasks and when everything is sorted, it is easier to read and understand the code.\n",
    "\n",
    "### `use_file` parameter/argument\n",
    "Along the way, you can see a parameter that is commonly used in the functions called `use_file=False`. This functionality of this parameter is just like its name. The problem that I have faced when working with the OMDb API is that while it is free for the public to use, they have imposed a 1,000 free daily requests limit. If you have subscribed to their Patreon, then you will have a higher request limit. Therefore, I have stored each dataset that I have extracted in an external `.csv` or `.txt` file in the following extraction functions. This also makes it easier for us to save any extraction progress (if anything goes wrong) and to see the data that has been extracted from the websites."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f511f26-3376-48ef-beec-aa5765b90750",
   "metadata": {},
   "source": [
    "### Crawling through the IMDb Top 250 Movies Page\n",
    "\n",
    "In this function, we will be using the Selenium library to data crawl and gather data from the Top 250 Movies page on the IMDb website. Previously, I tried to using BeautifulSoup. However, it has a limitation that restricts the amount of data that we can extract. The limitation is that it does not have features to load dynamic contents. This is why we pivot to using Selenium to extract data from IMDb. The function below extracts the titles of the top 250 movies from the webpage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c030c9f-ef71-4456-a6f4-b23c84fd3dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_crawl_top_250_movie_titles_IMDB(use_file=False):\n",
    "    file_name = '../resources/top_250_movie_titles_IMDB.txt'\n",
    "    check_file_exists = os.path.isfile(file_name)\n",
    "    if use_file and check_file_exists:\n",
    "        print(\"IMDB DATA FILE EXISTS: READING...\", end=' ')\n",
    "        with open(file_name, 'r', encoding='utf-8-sig') as file:\n",
    "            data = file.read()\n",
    "            titles_list = data.split('\\n')\n",
    "            print(f\"DONE - {len(titles_list)} MOVIE TITLES IMPORTED\\n\")\n",
    "            return titles_list\n",
    "\n",
    "    print(\"EXTRACT: TOP 250 MOVIE TITLES -> IMDB\")\n",
    "    # create an option to run Chrome browser without opening one for this data crawling operation\n",
    "    op = webdriver.ChromeOptions()\n",
    "    '''\n",
    "    chrome_options = Options()\n",
    "    user_agent = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.50 Safari/537.36'\n",
    "    chrome_options.add_argument(f'user-agent={user_agent}')\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    chrome_options.add_argument('--window-size=1920,1080')\n",
    "    chrome_options.add_argument('--headless')\n",
    "    chrome_options.add_argument('--disable-gpu')\n",
    "    chrome_options.add_argument('--allow-running-insecure-content')\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    '''\n",
    "    # locate the driver and load it in\n",
    "    driver = webdriver.Chrome()#options=chrome_options)\n",
    "    # define the url of the google form and use the driver to open up the url\n",
    "    url = \"https://www.imdb.com/chart/top/?ref_=nv_mv_250\"\n",
    "    \n",
    "    driver.get(url)\n",
    "    driver.maximize_window()\n",
    "    driver.get_screenshot_as_file(\"screenshot.png\")\n",
    "    time.sleep(2)\n",
    "    time_before_extraction = datetime.now()\n",
    "    \n",
    "    # find the div where all the list of movies are placed in\n",
    "    movies = driver.find_elements(By.XPATH, '//ul[@role=\"presentation\"]//li//div//div//div//div//a//h3[@class=\"ipc-title__text\"]')\n",
    "    \n",
    "    # extract the movie titles of the top 250 movies\n",
    "    movies_list = []\n",
    "    for i in range(len(movies)):\n",
    "        movies_list.append(movies[i].get_attribute(\"innerHTML\"))\n",
    "    \n",
    "    time_diff = datetime.now() - time_before_extraction\n",
    "    driver.close()\n",
    "    print(f\"DONE - {len(movies_list)} MOVIE TITLES EXTRACTED -> IMDB - TIME TAKEN: {time_diff}\\n\")\n",
    "\n",
    "    with open(file_name, 'w', encoding='utf-8-sig') as file:\n",
    "        for title in movies_list:\n",
    "            file.write(f\"{title}\\n\")\n",
    "    \n",
    "    return movies_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1538257-d061-4f53-8f7b-21d0189e87c4",
   "metadata": {},
   "source": [
    "### Requesting data on the movies from OMDb API\n",
    "\n",
    "The second source of data is from the OMDb. Thankfully, they have an API which allows us to request data from their database. Based on the titles of the movies that we extracted from IMDb, we can get the basic information from OMDb such as the year the movies were released, the genres of the movies, the list of actors, awards won, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "20d72f2a-3341-45e2-8822-ee548bf8086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes a request to the OMDb API for data on a movie by providing the movie's title\n",
    "def request_movie_data_OMDB_API(title):\n",
    "    # get data from the API; replace url with target source\n",
    "    url = 'http://www.omdbapi.com/?t=' + title + '&plot=full&apikey=1c62e2da'\n",
    "\n",
    "    response = http.request('GET', url)\n",
    "    if response.status != 200:\n",
    "        print(f\"Failed to retrieve page. Status code: {response.status}\")\n",
    "        return {}\n",
    "\n",
    "    # decode json data/string into a Python dict object\n",
    "    data = json.loads(response.data.decode('utf-8-sig'))\n",
    "    return data\n",
    "\n",
    "# main function to gather all the movie's data from OMDb\n",
    "def gather_movies_data_OMDB_API(movies_list, use_file=False):\n",
    "    # read in the csv files if we have already done the API requests and stored the data in a csv file\n",
    "    file_name = '../resources/top_250_movies_OMDB.csv'\n",
    "    check_file_exists = os.path.isfile(file_name)\n",
    "    if use_file and check_file_exists:\n",
    "        print(\"OMDB DATA FILE EXISTS: READING...\", end=' ')\n",
    "        df = read_csv_to_dataframe(file_name)\n",
    "        print(f\"DONE - {len(df)} MOVIE DATA IMPORTED\\n\")\n",
    "        return df\n",
    "        \n",
    "    movie_titles = []\n",
    "    print(\"EXTRACT: MOVIE DATA -> OMDB API\")\n",
    "    \n",
    "    # need to remove the numbering in front of all the movie names\n",
    "    for i in range(len(movies_list)):\n",
    "        # find the first space char and only take the substring after that space char\n",
    "        space_index = movies_list[i].find(' ')\n",
    "        title = movies_list[i][space_index+1:]\n",
    "        # because we need to search the titles in the OMDB database via the URL, it requires the space chars to be replaced with plus symbol (+)\n",
    "        movie_titles.append(title.replace(' ', '+'))\n",
    "    \n",
    "    movies_data_list = []\n",
    "    time_before_extraction = datetime.now()\n",
    "    \n",
    "    for i in range(len(movie_titles)):\n",
    "        movie_dict = request_movie_data_OMDB_API(movie_titles[i])\n",
    "        if len(movie_dict) > 0 and movie_dict['Response'].lower() == 'true':\n",
    "            movies_data_list.append(movie_dict)\n",
    "        else:\n",
    "            print(f\"Movie title: {movie_titles[i].replace('+', ' ')} not found.\")\n",
    "    \n",
    "    # store the data from the API to a DataFrame\n",
    "    df = pd.json_normalize(movies_data_list)\n",
    "\n",
    "    # print extraction process and time taken info\n",
    "    time_diff = datetime.now() - time_before_extraction\n",
    "    print(f\"DONE - {len(movies_data_list)} MOVIE RECORDS EXTRACTED -> OMDB API - TIME TAKEN: {time_diff}\\n\")\n",
    "\n",
    "    # export DataFrame to a csv file\n",
    "    export_dataframe_to_csv(df, file_name)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b8ff2b-b48c-417f-b5be-e19bc02002cc",
   "metadata": {},
   "source": [
    "### Requesting data from the TMDB API\n",
    "\n",
    "The third source of data is from TMDB. Just like the OMDb, they also have an API which allows us to request data from their database. From this API, we need to extract data that were missing from the ones we collected from OMDb. We are also going to extract data for the actors who acted in the movies.\n",
    "\n",
    "The functions in the cell below are functions to make specific requests to the TMDB API such as the ID of the movie stored in their database, the actor's ID stored in their database, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d5e165ad-e35b-4c18-bcb9-ed1b33fb4628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve movie's TMDB ID from TMDB using title string. returns an integer\n",
    "def get_movie_id_using_title_year_tmdb(title, year):\n",
    "    temp = title.replace(' ', '%20')\n",
    "    url = \"https://api.themoviedb.org/3/search/movie?query=\" + temp + \"&include_adult=false&language=en-US&page=1&year=\" + str(year)\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response_dict = response.json()\n",
    "    if response_dict[\"total_results\"] > 0:\n",
    "        return response_dict[\"results\"][0][\"id\"]\n",
    "    # return -1 when no results are found\n",
    "    return -1\n",
    "\n",
    "# retrieve movie details from TMDB using the tmdbID integer. returns a dictionary\n",
    "def get_movie_details_using_tmdbID_tmdb(tmdb_id):\n",
    "    url = \"https://api.themoviedb.org/3/movie/\" + str(tmdb_id) + \"?language=en-US\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        return\n",
    "    response_dict = response.json()\n",
    "    return response_dict\n",
    "\n",
    "# retrieve actors of a movie from TMDB using the tmdb ID. returns a list of dictionaries \n",
    "def get_first_three_actors_movie_TMDB_API(tmdb_id):\n",
    "    url = \"https://api.themoviedb.org/3/movie/\" + str(tmdb_id) + \"/credits?language=en-US\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        return\n",
    "    response_dict = response.json()\n",
    "    return response_dict[\"cast\"][:3]\n",
    "\n",
    "# retrieve the total number of acting credits of an actor from TMDB using the actor's ID. returns an integer\n",
    "def get_number_of_acting_credits_TMDB_API(actor_id):\n",
    "    url = \"https://api.themoviedb.org/3/person/\" + str(actor_id) + \"/movie_credits?language=en-US\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        return 0\n",
    "    return len(response.json()[\"cast\"])\n",
    "\n",
    "# retrieve details about an actor from TMDB using the actor's ID. returns a list of dictionaries \n",
    "def get_actor_details_TMDB_API(actor_id):\n",
    "    url = \"https://api.themoviedb.org/3/person/\" + str(actor_id) + \"?language=en-US\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        return {}\n",
    "    response_dict = response.json()\n",
    "    return response_dict\n",
    "\n",
    "# retrieve the actor's id from TMDB using the actor's name. returns an integer\n",
    "def get_actor_id_TMDB_API(actor_name):\n",
    "    name = actor_name.replace(' ', '%20')\n",
    "    url = \"https://api.themoviedb.org/3/search/person?query=\" + name + \"&include_adult=false&language=en-US&page=1\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        return\n",
    "    response_dict = response.json()\n",
    "    #print(response_dict)\n",
    "    return response_dict[\"results\"][0][\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1404ea87-c49f-43f8-8587-167048221455",
   "metadata": {},
   "source": [
    "### The remaining functions in the cells below will gather the requested data from TMDB API and store them inside the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e80c4f5f-3710-4f6b-81bf-25bee9edefe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_movie_data_TMDB_API(movies_df, use_file=False):\n",
    "    file_name = '../resources/top_250_movies_TMDB.csv'\n",
    "    check_file_exists = os.path.isfile(file_name)\n",
    "    if use_file and check_file_exists:\n",
    "        print(\"TMDB DATA FILE EXISTS: READING...\", end=' ')\n",
    "        df = read_csv_to_dataframe(file_name)\n",
    "        print(f\"DONE - {len(df)} MOVIE DATA IMPORTED\\n\")\n",
    "        return df\n",
    "    \n",
    "    movie_tmdb_ids = []\n",
    "    print(\"EXTRACT: MOVIE DATA -> TMDB API\")\n",
    "    time_before_extraction = datetime.now()\n",
    "    \n",
    "    # request for the ids of the movies\n",
    "    for i in movies_df.index:\n",
    "        id = get_movie_id_using_title_year_tmdb(movies_df.loc[i, \"Title\"], movies_df.loc[i, \"Year\"])\n",
    "        if id == -1:\n",
    "            print(\"ID not found for movie: \" + movies_df.loc[i, \"Title\"])\n",
    "        movie_tmdb_ids.append(id)\n",
    "\n",
    "    movies_df.insert(2, \"tmdbID\", movie_tmdb_ids)\n",
    "    budget_list = []\n",
    "    revenue_list = []\n",
    "    \n",
    "    for i in movies_df.index:\n",
    "        id = movies_df.loc[i, \"tmdbID\"]\n",
    "        result_dict = get_movie_details_using_tmdbID_tmdb(id)\n",
    "        if result_dict == None:\n",
    "            budget_list.append('N/A')\n",
    "            revenue_list.append('N/A')\n",
    "        else:\n",
    "            budget_list.append(result_dict[\"budget\"])\n",
    "            revenue_list.append(result_dict[\"revenue\"])\n",
    "    \n",
    "    movies_df[\"Production\"] = budget_list\n",
    "    movies_df[\"BoxOffice\"] = revenue_list\n",
    "    time_diff = datetime.now() - time_before_extraction\n",
    "    print(f\"DONE - {len(movies_df)} MOVIE DATA EXTRACTED -> TMDB API - TIME TAKEN: {time_diff}\\n\")\n",
    "\n",
    "    export_dataframe_to_csv(movies_df, file_name)\n",
    "    return movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "252c9418-a991-4836-8819-fc6588da0af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_actors_id_TMDB_API(movies_df, use_file=False):\n",
    "    tmdb_file_name = '../resources/top_250_movies_TMDB_rev.csv'\n",
    "    actors_id_file_name = '../resources/actor_ids_TMDB.txt'\n",
    "    check_files_exists = os.path.isfile(tmdb_file_name) and os.path.isfile(actors_id_file_name)\n",
    "    if use_file and check_files_exists:\n",
    "        print(\"TMDB DATA FILE EXISTS: READING...\", end=' ')\n",
    "        new_movies_df = read_csv_to_dataframe(tmdb_file_name)\n",
    "        print(f\"DONE - {len(new_movies_df)} MOVIE DATA IMPORTED\\n\")\n",
    "        \n",
    "        print(\"ACTOR ID TEXT FILE EXISTS: READING...\", end=' ')\n",
    "        with open(actors_id_file_name, 'r', encoding='utf-8-sig') as file:\n",
    "            data = file.read()\n",
    "            id_list = data.split('\\n')\n",
    "            actors_dict = {id: {} for id in id_list}\n",
    "            print(f\"DONE - {len(actors_dict)} ACTOR IDs IMPORTED\\n\")\n",
    "        return new_movies_df, actors_dict\n",
    "    \n",
    "    actors_dict = {}\n",
    "    print(\"FETCH: ACTOR IDs -> TMDB API\")\n",
    "    time_before_extraction = datetime.now()\n",
    "    \n",
    "    actors_list = []\n",
    "    for i in movies_df.index:\n",
    "        id = movies_df.loc[i, \"tmdbID\"]\n",
    "        result_list = get_first_three_actors_movie_TMDB_API(id)\n",
    "        if result_list == None or len(result_list) < 3:\n",
    "            temp_list = movies_df.loc[i, \"Actors\"].split(', ')\n",
    "            actors_list.append(temp_list)\n",
    "            for actor in temp_list:\n",
    "                actor_id = get_actor_id_TMDB_API(actor)\n",
    "                if not actor_id in actors_dict:\n",
    "                    actors_dict[actor_id] = {}\n",
    "            continue\n",
    "            \n",
    "        temp_list = []\n",
    "        for actor_details in result_list:\n",
    "            actor_name = actor_details[\"name\"]\n",
    "            actor_id = actor_details[\"id\"]\n",
    "            temp_list.append(actor_name)\n",
    "            if not actor_id in actors_dict:\n",
    "                actors_dict[actor_id] = {}\n",
    "        actors_list.append(temp_list)\n",
    "\n",
    "    movies_df[\"Actors\"] = actors_list\n",
    "            \n",
    "    time_diff = datetime.now() - time_before_extraction\n",
    "    print(f\"DONE - {len(actors_dict.keys())} ACTOR IDs FETCHED -> TMDB API - TIME TAKEN: {time_diff}\\n\")\n",
    "\n",
    "    export_dataframe_to_csv(movies_df, tmdb_file_name)\n",
    "    with open(actors_id_file_name, 'w', encoding='utf-8-sig') as file:\n",
    "        for id in actors_dict.keys():\n",
    "            file.write(f\"{id}\\n\")\n",
    "    \n",
    "    return movies_df, actors_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c0a8ab3-c73d-4932-8cbf-ab75f3aeada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_actors_data_TMDB_API(actors_dict, use_file=False):\n",
    "    file_name = '../resources/actor_data_TMDB.csv'\n",
    "    check_file_exists = os.path.isfile(file_name)\n",
    "    if use_file and check_file_exists:\n",
    "        print(\"TMDB DATA FILE EXISTS: READING...\", end=' ')\n",
    "        df = read_csv_to_dataframe(file_name)\n",
    "        print(f\"DONE - {len(df)} ACTOR DATA IMPORTED\\n\")\n",
    "        return df\n",
    "    \n",
    "    print(\"EXTRACT: ACTOR DATA -> TMDB API\")\n",
    "    time_before_extraction = datetime.now()\n",
    "    num_of_acting_credits_list = []\n",
    "    for id in actors_dict.keys():\n",
    "        actors_dict[id] = get_actor_details_TMDB_API(id)\n",
    "        num_of_acting_credits_list.append(get_number_of_acting_credits_TMDB_API(id))\n",
    "        \n",
    "    time_diff = datetime.now() - time_before_extraction\n",
    "    print(f\"DONE - {len(actors_dict.keys())} ACTOR DATA EXTRACTED -> TMDB API - TIME TAKEN: {time_diff}\\n\")\n",
    "    df = pd.json_normalize(actors_dict.values())\n",
    "    df.insert(13, \"num_of_acting_credits\", num_of_acting_credits_list)\n",
    "\n",
    "    export_dataframe_to_csv(df, file_name)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8547496f-b082-46b8-9e76-d10cc2a0a078",
   "metadata": {},
   "source": [
    "## Main extraction function\n",
    "\n",
    "We are going to call all the above functions in an order:\n",
    "1. Data crawling for titles of the top 250 movies from the IMDb website\n",
    "2. Request data on the movies by their titles from the OMDb through their API\n",
    "3. Request data on the movies from the TMDB through their API\n",
    "4. Request the actor's ID from the TMDB through their API\n",
    "5. Request data on the actors from the TMDB through their API\n",
    "\n",
    "In the end, there will be two DataFrames; `movies_df` and `actors_df`, which stores the data for the top 250 movies and the actors who acted in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a74af925-9599-4b9f-a5b2-b69d76f94c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(using_stored_file=True):\n",
    "    titles_list = data_crawl_top_250_movie_titles_IMDB(use_file=using_stored_file)\n",
    "    movies_df = gather_movies_data_OMDB_API(titles_list, use_file=using_stored_file)\n",
    "    movies_df = extract_movie_data_TMDB_API(movies_df, use_file=using_stored_file)\n",
    "\n",
    "    movies_df, actors_dict = get_all_actors_id_TMDB_API(movies_df, use_file=using_stored_file)\n",
    "    actors_df = extract_actors_data_TMDB_API(actors_dict, use_file=using_stored_file)\n",
    "    return movies_df, actors_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
